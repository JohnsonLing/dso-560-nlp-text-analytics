{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity Example\n",
    "\n",
    "### Intro to Algorithmic Marketing textbook example (Ilya Katsov):\n",
    "![alt text](../images/cos-sim-textbook1.png \"Logo Title Text 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Magnitude of a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approach: 3.7416573867739413\n",
      "Second approach: 3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def magnitude(x): \n",
    "    return math.sqrt(sum(i**2 for i in x))\n",
    "\n",
    "vectorA = [0,3,1,2]\n",
    "\n",
    "print(f\"First approach: {magnitude(vectorA)}\")\n",
    "print(f\"Second approach: {np.linalg.norm(vectorA)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Mutual Information\n",
    "\n",
    "It's important to identify a **context window** when analyzing co-occurence. In the image below, the context window size is 4 (2 tokens to either side of the target word). Example from [Nourchene Ouerhani](https://www.researchgate.net/figure/Example-The-quick-brown-fox-jumps-over-the-lazy-dog-Model-CBOW-Input-Layer-White_fig4_348558204):\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/context_window.png \"Logo Title Text 1\")\n",
    "\n",
    "For the purposes of the next section, we'll define the **entire document as the context window.**\n",
    "\n",
    "Pointwise mutual information measures the ratio between the **joint probability of two events happening** with the probabilities of the two events happening, assuming they are independent. It can be defined with the following equation:\n",
    "\n",
    "$$\n",
    "PMI_{A,B} = log\\frac{p(A,B)}{p(A)p(B)}\n",
    "$$\n",
    "\n",
    "Remember that when two events are independent, $P(i,j) = P(i)P(j)$. Using PMI to just a raw word count is often preferable because very common words have extreme skew (\"the\" and \"of\" will co-occur frequently in the same  )\n",
    "\n",
    "```python\n",
    "import math\n",
    "def pmi(tokenA, tokenB, documents, word_counts):\n",
    "    \n",
    "    # word_counts[token_A] => number of times tokenA appears in the documents\n",
    "    # float(len(documents)) => number of documents\n",
    "    # bigram_freq => a dictionary of the number of times tokenA and tokenB are in the same document together\n",
    "    \n",
    "    prob_A = word_counts[tokenA] / float(len(documents))\n",
    "    prob_B = word_counts[tokenB] / float(len(documents))\n",
    "    prob_A_B = bigram_freq[\" \".join([tokenA, tokenB])] / float(len(documents))\n",
    "    return math.log(prob_A_B/float(prob_A*prob_B),2) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation\n",
    "\n",
    "Many times, in previous homeworks, we've had to manually try to find phrases that belong together. For example, `New York City`.\n",
    "\n",
    "From [nltk.org](http://www.nltk.org/howto/collocations.html), **collocation** can be defined as\n",
    "\n",
    "> expressions of multiple words which commonly co-occur together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english') + [\".\",'.', \",\",\":\", \"''\", \"'s\", \"'\", \"``\", \"(\", \")\", \"-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "articles = [f\"../datasets/bbcsport/football/00{i}.txt\" for i in range(1,10)]\n",
    "\n",
    "for article in articles:\n",
    "    article = open(article) # open each sports article\n",
    "    for line in article.readlines():\n",
    "        line = line.replace(\"\\n\", \"\") # replace the new line escape character\n",
    "        if len(line) > 0: # if the line is not empty, process it\n",
    "            line = [lemmatizer.lemmatize(token) for token in word_tokenize(line)] \n",
    "            documents.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = []\n",
    "for doc in documents:\n",
    "    new_document = []\n",
    "    for word in doc:\n",
    "        if word.strip().lower() not in stopwords:\n",
    "            new_document.append(word)\n",
    "    new_documents.append(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Champions', 'League'),\n",
       " ('Manchester', 'United'),\n",
       " ('Cristiano', 'Ronaldo'),\n",
       " ('Van', 'Nistelrooy'),\n",
       " ('Wayne', 'Rooney'),\n",
       " ('Alex', 'Ferguson'),\n",
       " ('FA', 'Cup'),\n",
       " ('Ferguson', 'wa'),\n",
       " ('Gary', 'Neville'),\n",
       " ('Man', 'Utd'),\n",
       " ('Manchester', 'City'),\n",
       " ('Sir', 'Alex'),\n",
       " ('national', 'team'),\n",
       " ('wa', \"n't\"),\n",
       " ('23', 'minute')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_finder = BigramCollocationFinder.from_documents(new_documents)\n",
    "measures = BigramAssocMeasures()\n",
    "\n",
    "collocation_finder.nbest(measures.raw_freq, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
