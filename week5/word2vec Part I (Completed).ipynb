{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Spacy comes with a variety of different models that can used per language. For instance, the models for English are available [here](https://spacy.io/models/en). You'll need to download each model separately:\n",
    "\n",
    "```python\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download en_core_web_md\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code and example is from Ashiq KS's article [Rule-Based Matching with spacy](https://medium.com/@ashiqgiga07/rule-based-matching-with-spacy-295b76ca2b68):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input text string is converted to a Document object\n",
    "text = '''\n",
    "Computer programming is the process of writing instructions that get executed by computers. \n",
    "The instructions, also known as code, are written in a programming language which the computer \n",
    "can understand and use to perform a task or solve a problem. Basic computer programming involves \n",
    "the analysis of a problem and development of a logical sequence of instructions to solve it. \n",
    "There can be numerous paths to a solution and the computer programmer seeks to design and \n",
    "code that which is most efficient. Among the programmerâ€™s tasks are understanding requirements, \n",
    "determining the right programming language to use, designing or architecting the solution, coding, \n",
    "testing, debugging and writing documentation so that the solution can be easily\n",
    "understood by other programmers.Computer programming is at the heart of computer science. It is the \n",
    "implementation portion of software development, application development \n",
    "and software engineering efforts, transforming ideas and theories into actual, working solutions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher #import Matcher class from spacy\n",
    "#import the Span class to extract the words from the document object\n",
    "from spacy.tokens import Span \n",
    "\n",
    "#Language class with the English model 'en_core_web_sm' is loaded\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text) # convert the string above to a document\n",
    "\n",
    "#instantiate a new Matcher class object \n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Target Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pattern` object that you define should be a list of dictionary elements, each dictionary describing the token to match for. \n",
    "\n",
    "Here, we are matching for the usage of `computer` as a `NOUN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the pattern\n",
    "pattern = [{'LOWER': 'computer', 'POS': 'NOUN'},\n",
    "             {'POS':{'NOT_IN': ['VERB']}}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Pattern into the Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the pattern to the previously created matcher object\n",
    "matcher.add(\"Matching\", None, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regular Expressions in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below example can be found at https://spacy.io/usage/rule-based-matching. It uses the `re.finditer()` function to\n",
    "quickly iterate through all the matches found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: United States\n",
      "Found match: United States\n",
      "Found match: US\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
    "\n",
    "expression = r\"\\b[Uu](nited|\\.?) ?[Ss](tates|\\.?)\\b\"\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alphanumeric</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jobs</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>conj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma part_of_speech  tag dependency  shape  is_alphanumeric  \\\n",
       "0  Steve  Steve          PROPN  NNP   compound  Xxxxx             True   \n",
       "1   Jobs   Jobs          PROPN  NNP      nsubj   Xxxx             True   \n",
       "2    and    and          CCONJ   CC         cc    xxx             True   \n",
       "3  Apple  Apple          PROPN  NNP       conj  Xxxxx             True   \n",
       "4     is     be            AUX  VBZ        aux     xx             True   \n",
       "\n",
       "   is_stopword  \n",
       "0        False  \n",
       "1        False  \n",
       "2         True  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rows = []\n",
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    rows.append((token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "    \n",
    "data = pd.DataFrame(rows, columns=[\"text\", \"lemma\", \"part_of_speech\", \"tag\", \"dependency\", \"shape\", \"is_alphanumeric\", \"is_stopword\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from spacy docs\n",
    "doc = nlp(u\"Steve Jobs and Apple is looking at buying U.K. startup for $1 billion\")\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize this using displacy:\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings (word2vec Introduction) from Intro to Algorithmic Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words (Use Context to Predict Target Word)\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/word2vec_cbow.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/softmax.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/skipgram.png \"Logo Title Text 1\")\n",
    "\n",
    "## Softmax\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/wordembedding_cluster.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.5035 -4.4334 -3.5839 -1.1924 -2.6549]\n",
      "[ 3.9661 -3.784  -1.7973  4.8387 -3.1422]\n",
      "[ 1.6477  -0.62039  0.49445  0.59497  0.21123]\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(\"cake pie cookie\"):\n",
    "    for token2 in nlp(\"cake pie cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import en_core_web_md\n",
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dog - cat: 0.8220816850662231\n",
      " dog - Beijing: 0.002425447339192033\n",
      " dog - sad: 0.07570135593414307\n",
      " dog - depressed: 0.03279789537191391\n",
      " dog - couch: 0.3259493410587311\n",
      " dog - sofa: 0.23664459586143494\n",
      " dog - canine: 0.719451904296875\n",
      " dog - China: -0.04230016842484474\n",
      " dog - Chinese: -0.029234278947114944\n",
      " dog - France: -0.06262815743684769\n",
      " dog - Paris: -0.05884140357375145\n",
      " dog - banana: 0.2090904712677002\n",
      " cat - dog: 0.8220816850662231\n",
      " cat - Beijing: -0.01780039817094803\n",
      " cat - sad: 0.1828613430261612\n",
      " cat - depressed: 0.03235473856329918\n",
      " cat - couch: 0.38777071237564087\n",
      " cat - sofa: 0.31662240624427795\n",
      " cat - canine: 0.6167997121810913\n",
      " cat - China: -0.004194827750325203\n",
      " cat - Chinese: 0.005479123443365097\n",
      " cat - France: -0.12037640064954758\n",
      " cat - Paris: -0.026788583025336266\n",
      " cat - banana: 0.2235882729291916\n",
      " Beijing - dog: 0.002425447339192033\n",
      " Beijing - cat: -0.01780039817094803\n",
      " Beijing - sad: -0.07578963041305542\n",
      " Beijing - depressed: 0.15482419729232788\n",
      " Beijing - couch: -0.09267827123403549\n",
      " Beijing - sofa: -0.09635340422391891\n",
      " Beijing - canine: 0.0005792342708446085\n",
      " Beijing - China: 0.7576244473457336\n",
      " Beijing - Chinese: 0.656322181224823\n",
      " Beijing - France: 0.3342233896255493\n",
      " Beijing - Paris: 0.36522090435028076\n",
      " Beijing - banana: -0.05248577520251274\n",
      " sad - dog: 0.07570135593414307\n",
      " sad - cat: 0.1828613430261612\n",
      " sad - Beijing: -0.07578963041305542\n",
      " sad - depressed: 0.3065929412841797\n",
      " sad - couch: 0.12397421151399612\n",
      " sad - sofa: 0.06922245025634766\n",
      " sad - canine: -0.004827274475246668\n",
      " sad - China: -0.05402936413884163\n",
      " sad - Chinese: -0.09933916479349136\n",
      " sad - France: -0.14502935111522675\n",
      " sad - Paris: -0.05277536064386368\n",
      " sad - banana: 0.09653806686401367\n",
      " depressed - dog: 0.03279789537191391\n",
      " depressed - cat: 0.03235473856329918\n",
      " depressed - Beijing: 0.15482419729232788\n",
      " depressed - sad: 0.3065929412841797\n",
      " depressed - couch: 0.03174722194671631\n",
      " depressed - sofa: -0.0482107438147068\n",
      " depressed - canine: 0.1290651559829712\n",
      " depressed - China: 0.2392738163471222\n",
      " depressed - Chinese: 0.24559326469898224\n",
      " depressed - France: 0.287264883518219\n",
      " depressed - Paris: 0.06793149560689926\n",
      " depressed - banana: 0.05597629025578499\n",
      " couch - dog: 0.3259493410587311\n",
      " couch - cat: 0.38777071237564087\n",
      " couch - Beijing: -0.09267827123403549\n",
      " couch - sad: 0.12397421151399612\n",
      " couch - depressed: 0.03174722194671631\n",
      " couch - sofa: 0.8376800417900085\n",
      " couch - canine: 0.18913139402866364\n",
      " couch - China: -0.09443321824073792\n",
      " couch - Chinese: -0.0985521450638771\n",
      " couch - France: -0.11813614517450333\n",
      " couch - Paris: -0.03868206590414047\n",
      " couch - banana: 0.2754875719547272\n",
      " sofa - dog: 0.23664459586143494\n",
      " sofa - cat: 0.31662240624427795\n",
      " sofa - Beijing: -0.09635340422391891\n",
      " sofa - sad: 0.06922245025634766\n",
      " sofa - depressed: -0.0482107438147068\n",
      " sofa - couch: 0.8376800417900085\n",
      " sofa - canine: 0.15772858262062073\n",
      " sofa - China: -0.062092941254377365\n",
      " sofa - Chinese: -0.06429795920848846\n",
      " sofa - France: -0.053571637719869614\n",
      " sofa - Paris: -0.010519130155444145\n",
      " sofa - banana: 0.1568748950958252\n",
      " canine - dog: 0.719451904296875\n",
      " canine - cat: 0.6167997121810913\n",
      " canine - Beijing: 0.0005792342708446085\n",
      " canine - sad: -0.004827274475246668\n",
      " canine - depressed: 0.1290651559829712\n",
      " canine - couch: 0.18913139402866364\n",
      " canine - sofa: 0.15772858262062073\n",
      " canine - China: -0.0055264756083488464\n",
      " canine - Chinese: 0.04628412798047066\n",
      " canine - France: 0.04465959221124649\n",
      " canine - Paris: -0.012042265385389328\n",
      " canine - banana: 0.09559355676174164\n",
      " China - dog: -0.04230016842484474\n",
      " China - cat: -0.004194827750325203\n",
      " China - Beijing: 0.7576244473457336\n",
      " China - sad: -0.05402936413884163\n",
      " China - depressed: 0.2392738163471222\n",
      " China - couch: -0.09443321824073792\n",
      " China - sofa: -0.062092941254377365\n",
      " China - canine: -0.0055264756083488464\n",
      " China - Chinese: 0.7596927881240845\n",
      " China - France: 0.46787479519844055\n",
      " China - Paris: 0.17898134887218475\n",
      " China - banana: 0.06955646723508835\n",
      " Chinese - dog: -0.029234278947114944\n",
      " Chinese - cat: 0.005479123443365097\n",
      " Chinese - Beijing: 0.656322181224823\n",
      " Chinese - sad: -0.09933916479349136\n",
      " Chinese - depressed: 0.24559326469898224\n",
      " Chinese - couch: -0.0985521450638771\n",
      " Chinese - sofa: -0.06429795920848846\n",
      " Chinese - canine: 0.04628412798047066\n",
      " Chinese - China: 0.7596927881240845\n",
      " Chinese - France: 0.380295991897583\n",
      " Chinese - Paris: 0.15211237967014313\n",
      " Chinese - banana: 0.09432801604270935\n",
      " France - dog: -0.06262815743684769\n",
      " France - cat: -0.12037640064954758\n",
      " France - Beijing: 0.3342233896255493\n",
      " France - sad: -0.14502935111522675\n",
      " France - depressed: 0.287264883518219\n",
      " France - couch: -0.11813614517450333\n",
      " France - sofa: -0.053571637719869614\n",
      " France - canine: 0.04465959221124649\n",
      " France - China: 0.46787479519844055\n",
      " France - Chinese: 0.380295991897583\n",
      " France - Paris: 0.6351409554481506\n",
      " France - banana: -0.010739622637629509\n",
      " Paris - dog: -0.05884140357375145\n",
      " Paris - cat: -0.026788583025336266\n",
      " Paris - Beijing: 0.36522090435028076\n",
      " Paris - sad: -0.05277536064386368\n",
      " Paris - depressed: 0.06793149560689926\n",
      " Paris - couch: -0.03868206590414047\n",
      " Paris - sofa: -0.010519130155444145\n",
      " Paris - canine: -0.012042265385389328\n",
      " Paris - China: 0.17898134887218475\n",
      " Paris - Chinese: 0.15211237967014313\n",
      " Paris - France: 0.6351409554481506\n",
      " Paris - banana: -0.05507303774356842\n",
      " banana - dog: 0.2090904712677002\n",
      " banana - cat: 0.2235882729291916\n",
      " banana - Beijing: -0.05248577520251274\n",
      " banana - sad: 0.09653806686401367\n",
      " banana - depressed: 0.05597629025578499\n",
      " banana - couch: 0.2754875719547272\n",
      " banana - sofa: 0.1568748950958252\n",
      " banana - canine: 0.09559355676174164\n",
      " banana - China: 0.06955646723508835\n",
      " banana - Chinese: 0.09432801604270935\n",
      " banana - France: -0.010739622637629509\n",
      " banana - Paris: -0.05507303774356842\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'dog cat Beijing sad depressed couch sofa canine China Chinese France Paris banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if token1 != token2:\n",
    "            print(f\" {token1} - {token2}: {1 - cosine(token1.vector, token2.vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Most Similar Words (Using Our Old Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# inspect the default settings for CountVectorizer\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchen/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>adult</th>\n",
       "      <th>advertised</th>\n",
       "      <th>ago</th>\n",
       "      <th>air</th>\n",
       "      <th>amazon</th>\n",
       "      <th>apart</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  actual  actually  adult  advertised  ago  air  amazon  \\\n",
       "0     0           0       0         0      0           0    0    0       0   \n",
       "1     0           0       0         0      0           0    0    0       0   \n",
       "2     0           0       0         0      0           0    0    0       0   \n",
       "3     0           0       0         0      0           0    0    0       0   \n",
       "4     0           0       0         0      0           1    0    0       0   \n",
       "\n",
       "   apart  ...  working  works  worse  worst  worth  wouldn  wrong  year  \\\n",
       "0      0  ...        0      0      0      0      0       0      0     0   \n",
       "1      0  ...        0      0      0      0      0       0      0     0   \n",
       "2      0  ...        0      0      0      0      0       0      0     0   \n",
       "3      0  ...        0      0      0      0      0       0      0     0   \n",
       "4      0  ...        0      0      0      0      0       0      0     0   \n",
       "\n",
       "   years  zero  \n",
       "0      0     0  \n",
       "1      0     0  \n",
       "2      0     0  \n",
       "3      0     0  \n",
       "4      0     0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reviews = open(\"../datasets/poor_amazon_toy_reviews.txt\").readlines()\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                             stop_words=\"english\", \n",
    "                             max_features=500,token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b')\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "data = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchen/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create similiarity matrix\n",
    "similarity_matrix = pd.DataFrame(cosine_similarity(data.T.values), \n",
    "             columns=vectorizer.get_feature_names(),\n",
    "                                 index=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack matrix into table\n",
    "similarity_table = similarity_matrix.rename_axis(None).rename_axis(None, axis=1).stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns\n",
    "similarity_table.columns = [\"word1\", \"word2\", \"similarity\"]\n",
    "similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249500, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_table = similarity_table[similarity_table[\"similarity\"] < 0.99]\n",
    "similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144497</th>\n",
       "      <td>old</td>\n",
       "      <td>year</td>\n",
       "      <td>0.754569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194593</th>\n",
       "      <td>service</td>\n",
       "      <td>customer</td>\n",
       "      <td>0.734095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237276</th>\n",
       "      <td>waste</td>\n",
       "      <td>money</td>\n",
       "      <td>0.655483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245419</th>\n",
       "      <td>working</td>\n",
       "      <td>stopped</td>\n",
       "      <td>0.589414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>figure</td>\n",
       "      <td>figures</td>\n",
       "      <td>0.553856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>arm</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172826</th>\n",
       "      <td>quality</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.469081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179083</th>\n",
       "      <td>remote</td>\n",
       "      <td>control</td>\n",
       "      <td>0.456930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210121</th>\n",
       "      <td>store</td>\n",
       "      <td>dollar</td>\n",
       "      <td>0.426935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>apart</td>\n",
       "      <td>fell</td>\n",
       "      <td>0.385922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word1     word2  similarity\n",
       "144497      old      year    0.754569\n",
       "194593  service  customer    0.734095\n",
       "237276    waste     money    0.655483\n",
       "245419  working   stopped    0.589414\n",
       "74650    figure   figures    0.553856\n",
       "5949        arm     train    0.500379\n",
       "172826  quality      poor    0.469081\n",
       "179083   remote   control    0.456930\n",
       "210121    store    dollar    0.426935\n",
       "4648      apart      fell    0.385922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_table.sort_values(by=\"similarity\", ascending=False).drop_duplicates(\n",
    "    subset=\"similarity\", keep=\"first\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchen/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "top_500_words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Similar Words Using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into spacy your top 500 words\n",
    "\n",
    "tokens = nlp(f'{\" \".join(top_500_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# create a list of similarity tuples\n",
    "\n",
    "similarity_tuples = []\n",
    "\n",
    "for token1, token2 in product(tokens, repeat=2):\n",
    "    similarity_tuples.append((token1, token2, token1.similarity(token2)))\n",
    "\n",
    "similarities = pd.DataFrame(similarity_tuples, columns=[\"word1\",\"word2\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150235</th>\n",
       "      <td>overpriced</td>\n",
       "      <td>expensive</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54728</th>\n",
       "      <td>didn</td>\n",
       "      <td>aren</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242244</th>\n",
       "      <td>weeks</td>\n",
       "      <td>months</td>\n",
       "      <td>0.945185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48876</th>\n",
       "      <td>daughter</td>\n",
       "      <td>granddaughter</td>\n",
       "      <td>0.939131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218073</th>\n",
       "      <td>terrible</td>\n",
       "      <td>horrible</td>\n",
       "      <td>0.934416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word1          word2     score\n",
       "150235  overpriced      expensive  1.000000\n",
       "54728         didn           aren  1.000000\n",
       "242244       weeks         months  0.945185\n",
       "48876     daughter  granddaughter  0.939131\n",
       "218073    terrible       horrible  0.934416"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find similar words\n",
    "similarities[similarities[\"score\"] < 1].sort_values(\n",
    "    by=\"score\", ascending=False).drop_duplicates(\n",
    "    subset=\"score\", keep=\"first\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding The Most Similar Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "doc_similarities = pd.DataFrame(cosine_similarity(data[:500].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similarity_table = doc_similarities.rename_axis(\"doc1\").rename_axis(\"doc2\", axis=1).stack().reset_index()\n",
    "doc_similarity_table.columns = [\"doc1\", \"doc2\", \"similarity\"]\n",
    "doc_similarity_table = doc_similarity_table[doc_similarity_table[\"similarity\"] < 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54002</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>0.944911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>446</td>\n",
       "      <td>406</td>\n",
       "      <td>0.894427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195639</th>\n",
       "      <td>391</td>\n",
       "      <td>139</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103311</th>\n",
       "      <td>206</td>\n",
       "      <td>311</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223261</th>\n",
       "      <td>446</td>\n",
       "      <td>261</td>\n",
       "      <td>0.790569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207706</th>\n",
       "      <td>415</td>\n",
       "      <td>206</td>\n",
       "      <td>0.774597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158811</th>\n",
       "      <td>317</td>\n",
       "      <td>311</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147808</th>\n",
       "      <td>295</td>\n",
       "      <td>308</td>\n",
       "      <td>0.746004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99116</th>\n",
       "      <td>198</td>\n",
       "      <td>116</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219981</th>\n",
       "      <td>439</td>\n",
       "      <td>481</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc1  doc2  similarity\n",
       "54002    108     2    0.944911\n",
       "223406   446   406    0.894427\n",
       "195639   391   139    0.866025\n",
       "103311   206   311    0.816497\n",
       "223261   446   261    0.790569\n",
       "207706   415   206    0.774597\n",
       "158811   317   311    0.750000\n",
       "147808   295   308    0.746004\n",
       "99116    198   116    0.707107\n",
       "219981   439   481    0.707107"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_similarity_table.sort_values(by=\"similarity\", ascending=False).drop_duplicates(\n",
    "    subset=\"similarity\", keep=\"first\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"These packs are so overpriced for what you get, and you need packs 3-5 if you want access to the player aids for the Factions expansion. The base game of Alien Frontiers just plays so much smoother than adding Factions with these expansion packs.\"\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You need expansion packs 3-5 if you want access to the player aids for the Factions expansion. The base game of Alien Frontiers just plays so much smoother than adding Factions with the expansion packs. All this will do is pigeonhole you into a certain path to victory.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarities Using Word2Vec (Bag of Words Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [nlp(review).vector for review in reviews[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word2vec_doc_similarities = pd.DataFrame(cosine_similarity(np.array(vectors)))\n",
    "word2vec_doc_similarities_table = word2vec_doc_similarities.rename_axis(\n",
    "    \"doc1\").rename_axis(\"doc2\", axis=1).stack().reset_index()\n",
    "\n",
    "word2vec_doc_similarities_table.columns = [\"doc1\", \"doc2\", \"similarity\"]\n",
    "word2vec_doc_similarities_table = word2vec_doc_similarities_table[\n",
    "    word2vec_doc_similarities_table[\"similarity\"] < 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236720</th>\n",
       "      <td>473</td>\n",
       "      <td>220</td>\n",
       "      <td>0.976603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222914</th>\n",
       "      <td>445</td>\n",
       "      <td>414</td>\n",
       "      <td>0.974119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55082</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>0.971740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151720</th>\n",
       "      <td>303</td>\n",
       "      <td>220</td>\n",
       "      <td>0.970441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207493</th>\n",
       "      <td>414</td>\n",
       "      <td>493</td>\n",
       "      <td>0.970324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51582</th>\n",
       "      <td>103</td>\n",
       "      <td>82</td>\n",
       "      <td>0.969886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24202</th>\n",
       "      <td>48</td>\n",
       "      <td>202</td>\n",
       "      <td>0.969799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22610</th>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>0.969380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187794</th>\n",
       "      <td>375</td>\n",
       "      <td>294</td>\n",
       "      <td>0.968992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10526</th>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>0.968710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc1  doc2  similarity\n",
       "236720   473   220    0.976603\n",
       "222914   445   414    0.974119\n",
       "55082    110    82    0.971740\n",
       "151720   303   220    0.970441\n",
       "207493   414   493    0.970324\n",
       "51582    103    82    0.969886\n",
       "24202     48   202    0.969799\n",
       "22610     45   110    0.969380\n",
       "187794   375   294    0.968992\n",
       "10526     21    26    0.968710"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_doc_similarities_table.sort_values(by=\"similarity\", ascending=False).drop_duplicates(\n",
    "    subset=\"similarity\", keep=\"first\").head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
